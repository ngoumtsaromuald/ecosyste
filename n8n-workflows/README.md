# ü§ñ N8N Workflows pour RomAPI

Ce dossier contient les workflows n8n pour automatiser le scraping d'entreprises camerounaises et alimenter la base de donn√©es RomAPI.

## üìã Workflows Disponibles

### 1. `cameroon-business-scraper.json`
**Objectif :** Scraper les entreprises depuis les annuaires g√©n√©raux du Cameroun
- **Source :** pagesjaunes.cm et autres annuaires nationaux
- **Fr√©quence :** Quotidienne (configur√©e dans l'orchestrateur)
- **Donn√©es extraites :** Nom, description, t√©l√©phone, email, adresse, site web, cat√©gorie
- **Rate limiting :** 2 secondes entre chaque requ√™te

### 2. `douala-business-scraper.json`
**Objectif :** Scraper sp√©cifiquement les entreprises de Douala
- **Source :** go.cm/douala et annuaires locaux
- **Sp√©cialisation :** Entreprises de la r√©gion du Littoral
- **G√©olocalisation :** Coordonn√©es GPS automatiques pour Douala
- **Rate limiting :** 3 secondes entre chaque requ√™te

### 3. `business-scraper-orchestrator.json`
**Objectif :** Orchestrer et planifier l'ex√©cution des scrapers
- **Planification :** Cron job quotidien √† 2h du matin
- **Logique :** Rotation des scrapers selon les jours de la semaine
- **Monitoring :** V√©rification de sant√© de l'API avant ex√©cution
- **Reporting :** G√©n√©ration de rapports d'ex√©cution

## üöÄ Installation et Configuration

### Pr√©requis
1. **N8N install√©** (version 1.0+)
2. **RomAPI backend** fonctionnel sur `http://localhost:3001`
3. **API Keys** configur√©es pour l'authentification

### √âtapes d'installation

1. **Importer les workflows dans N8N :**
   ```bash
   # D√©marrer N8N
   npx n8n start
   
   # Acc√©der √† l'interface : http://localhost:5678
   # Aller dans "Workflows" > "Import from file"
   # Importer chaque fichier .json
   ```

2. **Configurer les API Keys :**
   - Cr√©er une API Key dans RomAPI pour n8n
   - Remplacer `your-n8n-api-key-here` dans chaque workflow
   - Remplacer `your-admin-api-key-here` dans l'orchestrateur

3. **Configurer les credentials N8N :**
   ```javascript
   // Dans N8N > Settings > Credentials
   // Cr√©er un "HTTP Header Auth" credential
   {
     "name": "X-API-Key",
     "value": "votre-api-key-romapi"
   }
   ```

4. **Tester les workflows :**
   - Ex√©cuter manuellement chaque scraper
   - V√©rifier que les donn√©es arrivent dans RomAPI
   - Activer l'orchestrateur pour l'automatisation

## ‚öôÔ∏è Configuration Avanc√©e

### Personnalisation des Sources

Pour ajouter de nouvelles sources de scraping :

```javascript
// Dans le node "Parse Business Data"
// Adapter les s√©lecteurs CSS selon le site cible
$('.business-listing, .company-item, .listing-item').each((index, element) => {
  const $el = $(element);
  // Modifier les s√©lecteurs selon la structure HTML
});
```

### Gestion des Rate Limits

```javascript
// Ajuster les d√©lais selon les robots.txt des sites
{
  "amount": 2, // secondes
  "unit": "seconds"
}
```

### Filtrage et Validation

```javascript
// Personnaliser les crit√®res de validation
if (business.name && (business.phone || business.email || business.address)) {
  businesses.push(business);
}
```

## üìä Monitoring et Logs

### Logs d'Ex√©cution
- **Succ√®s :** `‚úÖ Business successfully added: [nom]`
- **Erreur :** `‚ùå Failed to add business: [erreur]`
- **Info :** `üìç [Ville] business processed: [nom]`

### M√©triques Importantes
- Nombre d'entreprises scrap√©es par session
- Taux de succ√®s des requ√™tes API
- Dur√©e d'ex√©cution des workflows
- Erreurs de parsing ou de validation

### Dashboard N8N
Acc√©der aux statistiques via :
- **Executions :** Historique des ex√©cutions
- **Logs :** D√©tails des erreurs
- **Metrics :** Performance des workflows

## üõ°Ô∏è Bonnes Pratiques

### Respect des Robots.txt
```javascript
// V√©rifier robots.txt avant scraping
const robotsUrl = new URL('/robots.txt', baseUrl).href;
// Impl√©menter la logique de respect des r√®gles
```

### Gestion des Erreurs
```javascript
// Retry logic pour les requ√™tes √©chou√©es
try {
  // Scraping logic
} catch (error) {
  console.log(`Erreur scraping: ${error.message}`);
  // Retry ou skip
}
```

### Anonymisation
```javascript
// Rotation des User-Agents
const userAgents = [
  'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
  'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
];
```

## üîß D√©pannage

### Probl√®mes Courants

1. **API Key invalide :**
   ```
   Error: 401 Unauthorized
   Solution: V√©rifier la cl√© API dans les credentials N8N
   ```

2. **Timeout de scraping :**
   ```
   Error: Request timeout
   Solution: Augmenter le timeout dans les param√®tres HTTP
   ```

3. **Parsing √©chou√© :**
   ```
   Error: Cannot read property of undefined
   Solution: V√©rifier les s√©lecteurs CSS du site cible
   ```

### Debug Mode
```javascript
// Activer les logs d√©taill√©s
console.log('Debug:', {
  url: currentUrl,
  businesses: businesses.length,
  errors: errorCount
});
```

## üìà √âvolutions Futures

- **Multi-langues :** Support fran√ßais/anglais
- **G√©olocalisation :** API Google Maps pour coordonn√©es pr√©cises
- **ML Classification :** Cat√©gorisation automatique intelligente
- **Duplicate Detection :** D√©tection et fusion des doublons
- **Real-time Updates :** Mise √† jour en temps r√©el des changements

## ü§ù Contribution

Pour contribuer aux workflows :
1. Fork le projet
2. Cr√©er une branche feature
3. Tester les modifications
4. Soumettre une pull request

---

**Note :** Ces workflows respectent les bonnes pratiques de scraping √©thique et les conditions d'utilisation des sites sources.